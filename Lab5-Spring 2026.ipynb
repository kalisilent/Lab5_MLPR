{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Instructions\n",
                "###### Follow the instructions given in comments prefixed with ## and write your code below that.\n",
                "###### Also fill the partial code in given blanks. \n",
                "###### Don't make any changes to the rest part of the codes\n",
                "\n",
                "### Answer the questions given at the end of this notebook within your report.\n",
                "\n",
                "### You would need to submit your GitHub repository link. Refer to the PDF document for the instructions and details.\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## import cv2\n",
                "import cv2\n",
                "## import numpy\n",
                "import numpy as np\n",
                "## import matplotlib pyplot\n",
                "import matplotlib.pyplot as plt\n",
                "## import KMeans cluster from sklearn\n",
                "from sklearn.cluster import KMeans\n",
                "## import distance from scipy.spatial\n",
                "from scipy.spatial import distance\n",
                "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Reading the image plaksha_Faculty.jpg\n",
                "img = cv2.imread('plaksha_Faculty.jpg')\n",
                "  \n",
                "## Convert the image to grayscale\n",
                "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "  \n",
                "# Loading the required haar-cascade xml classifier file\n",
                "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
                "  \n",
                "# Applying the face detection method on the grayscale image. \n",
                "## Change the parameters for better detection of faces in your case.\n",
                "faces_rect = face_cascade.detectMultiScale(gray_img, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
                " \n",
                "# Define the text and font parameters\n",
                "text = 'Face' ## The text you want to write\n",
                "font = cv2.FONT_HERSHEY_SIMPLEX  ## Font type\n",
                "font_scale = 0.5  ## Font scale factor\n",
                "font_color = (0, 0, 255)  ## Text color in BGR format (here, it's red)\n",
                "font_thickness = 1  ## Thickness of the text\n",
                "\n",
                "  \n",
                "# Iterating through rectangles of detected faces\n",
                "for (x, y, w, h) in faces_rect:\n",
                "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
                "    # Use cv2.putText to add the text to the image, Use text, font, font_scale, font_color, font_thickness here\n",
                "    cv2.putText(img, text, (x, y - 10), font, font_scale, font_color, font_thickness)\n",
                "    \n",
                "## Display the image and window title should be \"Total number of face detected are #\"  \n",
                "cv2.imshow('Total number of face detected are ' + str(len(faces_rect)), img)\n",
                "cv2.waitKey(0)\n",
                "cv2.destroyAllWindows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
                "# Extract face region features (Hue and Saturation)\n",
                "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) ## call the img and convert it from BGR to HSV and store in img_hsv\n",
                "hue_saturation = []\n",
                "face_images = []  # To store detected face images\n",
                "\n",
                "for (x, y, w, h) in faces_rect:\n",
                "    face = img_hsv[y:y + h, x:x + w]\n",
                "    hue = np.mean(face[:, :, 0])\n",
                "    saturation = np.mean(face[:, :, 1])\n",
                "    hue_saturation.append((hue, saturation))\n",
                "    face_images.append(face)\n",
                "\n",
                "hue_saturation = np.array(hue_saturation)\n",
                "\n",
                "## Perform k-Means clustering on hue_saturation and store in kmeans\n",
                "kmeans = KMeans(n_clusters=2, random_state=0).fit(hue_saturation)\n",
                "#centroids = kmeans.cluster_centers_\n",
                "#labels = kmeans.labels_\n",
                "\n",
                "# Create a figure and axis\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "# Plot the clustered faces with custom markers\n",
                "for i, (x,y,w,h ) in enumerate(faces_rect):\n",
                "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
                "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
                "    ax.add_artist(ab)\n",
                "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1])\n",
                "    \n",
                "\n",
                "## Put x label\n",
                "plt.xlabel('Hue')\n",
                "## Put y label\n",
                "plt.ylabel('Saturation')\n",
                "## Put title\n",
                "plt.title('Face Features - Hue vs Saturation')\n",
                "## Put grid\n",
                "plt.grid(True)\n",
                "## show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an empty list to store legend labels\n",
                "legend_labels = []\n",
                "\n",
                "# Create lists to store points for each cluster\n",
                "cluster_0_points = []\n",
                "cluster_1_points = []\n",
                "\n",
                "# Your code for scatter plot goes here\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "for i, (x, y, w, h) in enumerate(faces_rect):\n",
                "    if kmeans.labels_[i] == 0:\n",
                "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
                "    else:\n",
                "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
                "\n",
                "\n",
                "cluster_0_points = np.array(cluster_0_points)\n",
                "# Plot points for cluster 0 in green\n",
                "plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], c='green', label='Cluster 0', marker='o')\n",
                "\n",
                "\n",
                "cluster_1_points = np.array(cluster_1_points)\n",
                "# Plot points for cluster 1 in blue\n",
                "plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], c='blue', label='Cluster 1', marker='o')\n",
                "\n",
                "# Calculate and plot centroids\n",
                "centroid_0 = kmeans.cluster_centers_[0]\n",
                "centroid_1 = kmeans.cluster_centers_[1]\n",
                "\n",
                "# Plot both the centroid for cluster 0 and cluster 1 \n",
                "plt.scatter(centroid_0[0], centroid_0[1], c='red', marker='X', s=200, label='Centroid 0')\n",
                "plt.scatter(centroid_1[0], centroid_1[1], c='black', marker='X', s=200, label='Centroid 1')\n",
                "\n",
                "## Put x label\n",
                "plt.xlabel('Hue')\n",
                "## Put y label\n",
                "plt.ylabel('Saturation')\n",
                "## Put title\n",
                "plt.title('K-Means Clustering of Detected Faces (Hue vs Saturation)')\n",
                "## Add a legend\n",
                "plt.legend()\n",
                "## Add grid\n",
                "plt.grid(True)\n",
                "## Show the plot\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Read the class of the template image 'Dr_Shashi_Tharoor.jpg' using cv2 and store it in template_img\n",
                "template_img = cv2.imread('Dr_Shashi_Tharoor.jpg')\n",
                "# Detect face  in the template image after converting it to gray and store it in template_faces\n",
                "template_faces = face_cascade.detectMultiScale(cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY), 1.05, 4)\n",
                "# Draw rectangles around the detected faces\n",
                "for (x, y, w, h) in template_faces:\n",
                "    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
                "cv2.imshow('Template Image - Dr Shashi Tharoor - Faces Detected: ' + str(len(template_faces)), template_img)\n",
                "cv2.waitKey(0)\n",
                "cv2.destroyAllWindows()      "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the template image to HSV color space and store it in template_hsv\n",
                "template_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n",
                "\n",
                "# Extract hue and saturation features from the template image as we did it for detected faces.\n",
                "template_hue = np.mean(template_hsv[:, :, 0])\n",
                "template_saturation = np.mean(template_hsv[:, :, 1])\n",
                "\n",
                "# Predict the cluster label for the template image and store it in template_label\n",
                "template_label = kmeans.predict([[template_hue, template_saturation]])[0]\n",
                "\n",
                "# Create a figure and axis for visualization\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "# Plot the clustered faces with custom markers (similar to previous code)\n",
                "for i, (x, y, w, h) in enumerate(faces_rect):\n",
                "    color = 'red' if kmeans.labels_[i] == 0 else 'blue'\n",
                "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
                "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
                "    ax.add_artist(ab)\n",
                "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color=color)\n",
                "\n",
                "# Plot the template image in the respective cluster\n",
                "if template_label == 0:\n",
                "    color = 'red'\n",
                "else:\n",
                "    color = 'blue'\n",
                "im = OffsetImage(cv2.cvtColor(cv2.resize(template_img, (20, 20)), cv2.COLOR_BGR2RGB))\n",
                "ab = AnnotationBbox(im, (template_hue, template_saturation), frameon=False, pad=0)\n",
                "ax.add_artist(ab)\n",
                "\n",
                "## Put x label\n",
                "plt.xlabel('Hue')\n",
                "## Put y label\n",
                "plt.ylabel('Saturation')\n",
                "## Put title\n",
                "plt.title('Clustered Faces with Template Image')\n",
                "## Add grid\n",
                "plt.grid(True)\n",
                "## show plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an empty list to store legend labels\n",
                "legend_labels = []\n",
                "\n",
                "# Create lists to store points for each cluster\n",
                "cluster_0_points = []\n",
                "cluster_1_points = []\n",
                "\n",
                "# Your code for scatter plot goes here\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "for i, (x, y, w, h) in enumerate(faces_rect):\n",
                "    if kmeans.labels_[i] == 0:\n",
                "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
                "    else:\n",
                "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
                "\n",
                "# Plot points for cluster 0 in green\n",
                "cluster_0_points = np.array(cluster_0_points)\n",
                "plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], c='green', label='Cluster 0', marker='o')\n",
                "\n",
                "# Plot points for cluster 1 in blue\n",
                "cluster_1_points = np.array(cluster_1_points)\n",
                "plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], c='blue', label='Cluster 1', marker='o')\n",
                "\n",
                "# Calculate and plot centroids for both the clusters\n",
                "centroid_0 = kmeans.cluster_centers_[0]\n",
                "centroid_1 = kmeans.cluster_centers_[1]\n",
                "plt.scatter(centroid_0[0], centroid_0[1], c='red', marker='X', s=200, label='Centroid 0') ## plot for centroid 0\n",
                "plt.scatter(centroid_1[0], centroid_1[1], c='black', marker='X', s=200, label='Centroid 1')  ## plot for centroid 1\n",
                "plt.plot(template_hue, template_saturation, marker='o', c= 'violet',markersize= 10, label=' Class ?' )\n",
                "\n",
                "## Put x label\n",
                "plt.xlabel('Hue')\n",
                "## Put y label\n",
                "plt.ylabel('Saturation')\n",
                "## Put title\n",
                "plt.title('K-Means Clustering with Template Image Classification')\n",
                "## Add a legend\n",
                "plt.legend()\n",
                "## Add grid\n",
                "plt.grid(True)\n",
                "## show the plot\n",
                "plt.show()\n",
                "                                            ## End of the lab 5 ##"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Report:\n",
                "## Answer the following questions within your report:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1. What are the common distance metrics used in distance-based classification algorithms? \n",
                "\n",
                "The common distance metrics include:\n",
                "- **Euclidean Distance**: The straight-line distance between two points in n-dimensional space. It is the most widely used metric.\n",
                "- **Manhattan Distance (City Block / L1 Norm)**: The sum of absolute differences between the coordinates of two points.\n",
                "- **Minkowski Distance**: A generalized form of both Euclidean and Manhattan distance, parameterized by *p*.\n",
                "- **Cosine Similarity / Distance**: Measures the cosine of the angle between two vectors; useful for high-dimensional text data.\n",
                "- **Hamming Distance**: Counts the number of positions at which the corresponding symbols are different; commonly used for categorical or binary data.\n",
                "- **Chebyshev Distance (L∞ Norm)**: The maximum of the absolute differences between coordinates.\n",
                "- **Mahalanobis Distance**: Accounts for correlations between features and is scale-invariant.\n",
                "\n",
                "#### 2. What are some real-world applications of distance-based classification algorithms? \n",
                "\n",
                "- **Face recognition**: Classifying faces by comparing feature distances (as done in this lab).\n",
                "- **Recommendation systems**: Finding similar users or items (collaborative filtering with KNN).\n",
                "- **Medical diagnosis**: Classifying patients based on symptoms or biomarker similarity.\n",
                "- **Handwriting / digit recognition**: Classifying handwritten characters by comparing pixel feature distances (e.g., MNIST dataset).\n",
                "- **Anomaly / fraud detection**: Flagging transactions that are far from normal patterns.\n",
                "- **Gene expression analysis**: Grouping genes with similar expression profiles.\n",
                "- **Customer segmentation**: Clustering customers by purchasing behaviour using K-Means.\n",
                "\n",
                "#### 3. Explain various distance metrics. \n",
                "\n",
                "a) **Euclidean Distance**: This is the most common way to measure distance, like measuring the straight-line distance between two points on a piece of paper with a ruler. It calculates the shortest path between point A and point B. It works well when all features are numeric and have similar scales.\n",
                "\n",
                "b) **Manhattan Distance**: Imagine you are in a city with grid-like streets and you want to go from one intersection to another. You can't go through buildings, so you have to walk along the streets (horizontal + vertical distance). That sum of horizontal and vertical steps is the Manhattan distance. It is useful when your data has many dimensions or when outliers might mess up the Euclidean calculation.\n",
                "\n",
                "c) **Minkowski Distance**: This is a generalized form that combines both Euclidean and Manhattan distances. It uses a parameter 'p'. If p=1, it becomes Manhattan distance. If p=2, it becomes Euclidean distance. It gives you the flexibility to choose the best distance type for your problem.\n",
                "\n",
                "d) **Cosine Distance**: Instead of measuring how far apart two points are, this measures the angle between two vectors. Think of two arrows starting from the same point; if they point in the same direction, the distance is small (similarity is high), even if one arrow is much longer than the other. This is great for text analysis where the length of the document doesn't matter as much as the content.\n",
                "\n",
                "e) **Hamming Distance**: This is used for categorical data or computer strings. It simply counts the number of positions where two strings of equal length are different. For example, the Hamming distance between \"face\" and \"fact\" is 1 because only the last letter is different. It measures the minimum number of substitutions required to change one string into the other.\n",
                "\n",
                "f) **Chebyshev Distance**: Imagine playing chess; the King can move to any adjacent square (horizontal, vertical, or diagonal). The minimum number of moves the King needs to get from one square to another is the Chebyshev distance. Mathematically, it is simply the greatest single difference along any coordinate dimension.\n",
                "\n",
                "#### 4. What is the role of cross validation in model performance? \n",
                "\n",
                "Cross-validation is a technique used to assess how well a model generalizes to unseen data. Its roles include:\n",
                "- **Reducing overfitting**: By training and testing on different subsets, it detects models that memorize training data rather than learning general patterns.\n",
                "- **Hyperparameter tuning**: Helps select the best value of *k* in KNN or the number of clusters in K-Means.\n",
                "- **Reliable performance estimation**: Provides a more robust estimate of model accuracy than a single train-test split, since every data point is used for both training and testing across different folds.\n",
                "- **Efficient use of data**: Particularly valuable when the dataset is small, as it maximizes the use of available samples for both training and validation.\n",
                "\n",
                "Common methods include k-fold CV, stratified k-fold CV, and leave-one-out CV (LOOCV).\n",
                "\n",
                "#### 5. Explain variance and bias in terms of KNN? \n",
                "\n",
                "- **Bias** refers to errors due to overly simplistic assumptions in the model. In KNN, a **large value of k** (e.g., k = N) leads to **high bias** because the model averages over too many neighbors, effectively underfitting and ignoring local patterns.\n",
                "- **Variance** refers to sensitivity to fluctuations in the training data. A **small value of k** (e.g., k = 1) leads to **high variance** because the prediction depends on a single neighbor and is very sensitive to noise.\n",
                "- The **bias-variance tradeoff** in KNN is controlled by k:\n",
                "  - **Small k → Low bias, High variance** (complex, noisy decision boundary)\n",
                "  - **Large k → High bias, Low variance** (smooth, potentially underfitting boundary)\n",
                "- The optimal k balances this tradeoff and is typically found through cross-validation."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_minor": 2,
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}